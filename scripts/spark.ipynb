{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/09 13:50:12 WARN Utils: Your hostname, ngocthang-virtual-machine resolves to a loopback address: 127.0.1.1; using 192.168.29.130 instead (on interface ens33)\n",
      "24/06/09 13:50:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/09 13:50:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.29.130:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sales-analytics</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x75f6f8404040>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"sales-analytics\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_order = spark.read.option(\"header\", \"true\").option(\"quote\", '\"').csv(\"file:///home/ngocthang/Documents/Code/Sales-Analytics/sales-analytics/data/raw-data/orders.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+---------------------+-------------+---------+------------+----------------+---------------------------------+-------------------+\n",
      "|Customer ID|Customer Status|Date Order was placed|Delivery Date| Order ID|  Product ID|Quantity Ordered|Total Retail Price for This Order|Cost Price Per Unit|\n",
      "+-----------+---------------+---------------------+-------------+---------+------------+----------------+---------------------------------+-------------------+\n",
      "|        579|         Silver|            01-Jan-17|    07-Jan-17|123002578|220101400106|               2|                             92.6|               20.7|\n",
      "|       7574|         SILVER|            01-Jan-17|    05-Jan-17|123004074|210201000009|               1|                             21.7|               9.95|\n",
      "|      28861|           Gold|            01-Jan-17|    04-Jan-17|123000871|230100500068|               1|                              1.7|                0.8|\n",
      "|      43796|           Gold|            01-Jan-17|    06-Jan-17|123002851|220100100633|               1|                             47.9|              24.05|\n",
      "|      54673|           Gold|            01-Jan-17|    04-Jan-17|123003607|220200200043|               1|                             36.9|               18.3|\n",
      "+-----------+---------------+---------------------+-------------+---------+------------+----------------+---------------------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_order.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Customer ID: string (nullable = true)\n",
      " |-- Customer Status: string (nullable = true)\n",
      " |-- Date Order was placed: string (nullable = true)\n",
      " |-- Delivery Date: string (nullable = true)\n",
      " |-- Order ID: string (nullable = true)\n",
      " |-- Product ID: string (nullable = true)\n",
      " |-- Quantity Ordered: string (nullable = true)\n",
      " |-- Total Retail Price for This Order: string (nullable = true)\n",
      " |-- Cost Price Per Unit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_order.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "185013"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_order.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product = spark.read.\\\n",
    "    option(\"header\", \"true\")\\\n",
    "    .option(\"quote\", '\"')\\\n",
    "    .csv(\"file:///home/ngocthang/Documents/Code/Sales-Analytics/sales-analytics/data/raw-data/product-supplier.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5504"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-----------------+--------------------+--------------------+----------------+--------------------+-----------+\n",
      "|  Product ID|Product Line| Product Category|       Product Group|        Product Name|Supplier Country|       Supplier Name|Supplier ID|\n",
      "+------------+------------+-----------------+--------------------+--------------------+----------------+--------------------+-----------+\n",
      "|210100100001|    Children|Children Outdoors|Outdoor things, Kids|Boy's and Girl's ...|              NO|Scandinavian Clot...|         50|\n",
      "|210100100002|    Children|Children Outdoors|Outdoor things, Kids|   Children's Jacket|              ES| Luna sastreria S.A.|       4742|\n",
      "|210100100003|    Children|Children Outdoors|Outdoor things, Kids|Children's Jacket...|              NO|Scandinavian Clot...|         50|\n",
      "|210100100004|    Children|Children Outdoors|Outdoor things, Kids| Children's Rain Set|              NO|Scandinavian Clot...|         50|\n",
      "|210100100005|    Children|Children Outdoors|Outdoor things, Kids|Children's Rain Suit|              NO|Scandinavian Clot...|         50|\n",
      "+------------+------------+-----------------+--------------------+--------------------+----------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_product.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, date_format, col, when, udf, count, isnan\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAGE 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic cleanning  & formating data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order = df_order.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=============================>                             (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+---------------------+-------------+--------+----------+----------------+---------------------------------+-------------------+\n",
      "|Customer ID|Customer Status|Date Order was placed|Delivery Date|Order ID|Product ID|Quantity Ordered|Total Retail Price for This Order|Cost Price Per Unit|\n",
      "+-----------+---------------+---------------------+-------------+--------+----------+----------------+---------------------------------+-------------------+\n",
      "|          0|              0|                    0|            0|       0|         0|               0|                                0|                  0|\n",
      "+-----------+---------------+---------------------+-------------+--------+----------+----------------+---------------------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check if there is any wrong cloumn\n",
    "df_order.select([count(when(col(c).contains('None') | \\\n",
    "                            col(c).contains('NULL') | \\\n",
    "                            (col(c) == '' ) | \\\n",
    "                            col(c).isNull() | \\\n",
    "                            isnan(c), c \n",
    "                           )).alias(c)\n",
    "                    for c in df_order.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardize = udf(lambda s : s.capitalize(), StringType()) # Capitalize the first letter and convert the rest to lowercase\n",
    "# correct data type\n",
    "df_order_transform = df_order.withColumn(\"Date Order was placed\", to_date(\"Date Order was placed\", \"dd-MMM-yy\")) \\\n",
    "                            .withColumn(\"Delivery Date\", to_date(\"Delivery Date\", \"dd-MMM-yy\")) \\\n",
    "                            .withColumn(\"Customer Status\", standardize(\"Customer Status\")) \\\n",
    "                            .withColumn(\"Quantity Ordered\", col(\"Quantity Ordered\").cast(\"integer\"))\\\n",
    "                            .withColumn(\"Total Retail Price for This Order\", col(\"Total Retail Price for This Order\").cast(\"double\")) \\\n",
    "                            .withColumn(\"Cost Price Per Unit\", col(\"Cost Price Per Unit\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "f_order_transform = df_order_transform.withColumnRenamed(\"Date Order was placed\", \"Order Date\").\\\n",
    "                                        withColumnRenamed(\"Total Retail Price for This Order\", \"Order Price\").\\\n",
    "                                        withColumnRenamed(\"Cost Price Per Unit\", \"Cost Per Product\").\\\n",
    "                                        withColumnRenamed(\"Quantity Ordered\", \"Order Quantity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "185013"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_order_transform.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 154:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+----------+-------------+---------+------------+--------------+-----------+----------------+\n",
      "|Customer ID|Customer Status|Order Date|Delivery Date| Order ID|  Product ID|Order Quantity|Order Price|Cost Per Product|\n",
      "+-----------+---------------+----------+-------------+---------+------------+--------------+-----------+----------------+\n",
      "|      92956|         Silver|2017-01-02|   2017-01-02|123009195|230100100013|             2|      226.2|            58.9|\n",
      "|      62039|           Gold|2017-01-03|   2017-01-03|123013358|220100100036|             1|       41.2|            20.7|\n",
      "|      40267|         Silver|2017-01-05|   2017-01-05|123024632|210200600084|             1|       34.8|            14.9|\n",
      "|      50664|           Gold|2017-01-07|   2017-01-07|123037269|240800200043|             2|       84.6|           18.45|\n",
      "|      55786|         Silver|2017-01-07|   2017-01-07|123034300|210200600013|             1|       83.7|            41.8|\n",
      "+-----------+---------------+----------+-------------+---------+------------+--------------+-----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_order_transform.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+----------+-------------+---------+------------+--------------+-----------+----------------+\n",
      "|Customer ID|Customer Status|Order Date|Delivery Date| Order ID|  Product ID|Order Quantity|Order Price|Cost Per Product|\n",
      "+-----------+---------------+----------+-------------+---------+------------+--------------+-----------+----------------+\n",
      "|        579|         Silver|2018-09-28|   2018-09-28|123306088|240100100235|             1|       13.2|            5.65|\n",
      "|        579|         Silver|2017-01-01|   2017-01-07|123002578|220101400106|             2|       92.6|            20.7|\n",
      "|        579|         Silver|2021-09-24|   2021-09-24|124350126|220101400027|             2|      139.0|            31.7|\n",
      "|        579|           Gold|2021-04-29|   2021-04-29|124209728|240100100458|             1|        6.7|            2.95|\n",
      "+-----------+---------------+----------+-------------+---------+------------+--------------+-----------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_order_transform.filter(col(\"Customer ID\") == \"579\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Customer ID: string (nullable = true)\n",
      " |-- Customer Status: string (nullable = true)\n",
      " |-- Order Date: date (nullable = true)\n",
      " |-- Delivery Date: date (nullable = true)\n",
      " |-- Order ID: string (nullable = true)\n",
      " |-- Product ID: string (nullable = true)\n",
      " |-- Order Quantity: string (nullable = true)\n",
      " |-- Order Price: double (nullable = true)\n",
      " |-- Cost Per Product: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_order_transform.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product = df_product.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------------+-------------+------------+----------------+-------------+-----------+\n",
      "|Product ID|Product Line|Product Category|Product Group|Product Name|Supplier Country|Supplier Name|Supplier ID|\n",
      "+----------+------------+----------------+-------------+------------+----------------+-------------+-----------+\n",
      "|         0|           0|               0|            0|           0|               0|            0|          0|\n",
      "+----------+------------+----------------+-------------+------------+----------------+-------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# check if any row contains null or empty value\n",
    "df_product.select([count(when(col(c).contains('None') | \\\n",
    "                            col(c).contains('NULL') | \\\n",
    "                            (col(c) == '' ) | \\\n",
    "                            col(c).isNull() | \\\n",
    "                            isnan(c), c \n",
    "                           )).alias(c)\n",
    "                    for c in df_product.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "# generate a new column contains name of country values base on Supplier Country Name  column\n",
    "def get_country_name(country_code):\n",
    "    try:\n",
    "        country = pycountry.countries.get(alpha_2=country_code)\n",
    "        if country:\n",
    "            return country.name\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "get_country_name_udf = udf(get_country_name, StringType())\n",
    "\n",
    "# Apply the UDF to the DataFrame column\n",
    "\n",
    "df_product_transform = df_product.withColumn(\"Supplier Country Name\", get_country_name_udf(col(\"Supplier Country\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_transform = df_product_transform.withColumnRenamed(\"Supplier Country\", \"Supplier Country Code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Product ID: string (nullable = true)\n",
      " |-- Product Line: string (nullable = true)\n",
      " |-- Product Category: string (nullable = true)\n",
      " |-- Product Group: string (nullable = true)\n",
      " |-- Product Name: string (nullable = true)\n",
      " |-- Supplier Country Code: string (nullable = true)\n",
      " |-- Supplier Name: string (nullable = true)\n",
      " |-- Supplier ID: string (nullable = true)\n",
      " |-- Supplier Country Name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_product_transform.printSchema() # check data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+----------------+----------------+--------------------+---------------------+--------------------+-----------+---------------------+\n",
      "|  Product ID|   Product Line|Product Category|   Product Group|        Product Name|Supplier Country Code|       Supplier Name|Supplier ID|Supplier Country Name|\n",
      "+------------+---------------+----------------+----------------+--------------------+---------------------+--------------------+-----------+---------------------+\n",
      "|210200900019|       Children| Children Sports|    Osprey, Kids|Osprey Cellerator...|                   US|Triple Sportswear...|       3664|        United States|\n",
      "|220100100113|Clothes & Shoes|         Clothes|Eclipse Clothing|Big Guy Men's Col...|                   US|         Eclipse Inc|       1303|        United States|\n",
      "|220100100252|Clothes & Shoes|         Clothes|Eclipse Clothing|Big Guy Men's Sol...|                   US|         Eclipse Inc|       1303|        United States|\n",
      "|220100100264|Clothes & Shoes|         Clothes|Eclipse Clothing|Big Guy Men's Swe...|                   US|         Eclipse Inc|       1303|        United States|\n",
      "|220100100459|Clothes & Shoes|         Clothes|Eclipse Clothing|Watchit 42 Black/...|                   US|         Eclipse Inc|       1303|        United States|\n",
      "+------------+---------------+----------------+----------------+--------------------+---------------------+--------------------+-----------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_product_transform.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load stage files to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_order_parquet = df_order_transform.repartition(1)\n",
    "df_order_parquet.write.mode('overwrite').parquet(\"D:\\Code\\DataEngieering-Projects\\Projects\\Sales-Analytics\\data\\data-transformed\\order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_parquet = df_product_transform.repartition(1)\n",
    "df_product_parquet.write.mode('overwrite').parquet(\"D:\\Code\\DataEngieering-Projects\\Projects\\Sales-Analytics\\data\\data-transformed\\product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAGE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data on following schema "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dimCountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+\n",
      "|countryID|   countryName|\n",
      "+---------+--------------+\n",
      "|       NO|        Norway|\n",
      "|       SE|        Sweden|\n",
      "|       DE|       Germany|\n",
      "|       FR|        France|\n",
      "|       NL|   Netherlands|\n",
      "|       GB|United Kingdom|\n",
      "|       AU|     Australia|\n",
      "|       DK|       Denmark|\n",
      "|       US| United States|\n",
      "|       CA|        Canada|\n",
      "|       PT|      Portugal|\n",
      "|       ES|         Spain|\n",
      "|       BE|       Belgium|\n",
      "+---------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dimCountry = df_product_transform.select(col(\"Supplier Country Code\").alias(\"countryID\"), col(\"Supplier Country Name\").alias(\"countryName\")).distinct()\n",
    "dimCountry.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- countryID: string (nullable = true)\n",
      " |-- countryName: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check the format of datatype \n",
    "dimCountry.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dimSupplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product_transform.select(col(\"Supplier ID\")).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----------------+\n",
      "|supplierID|        supplierName|supplierCountryID|\n",
      "+----------+--------------------+-----------------+\n",
      "|     12869|Truls Sporting Goods|               NO|\n",
      "|      5922|        Force Sports|               BE|\n",
      "|      7511|  Mike Schaeffer Inc|               US|\n",
      "|     13314|         Triffy B.V.|               NL|\n",
      "|     18009|     SportPharma Inc|               US|\n",
      "+----------+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimSupplier = df_product_transform.select(col(\"Supplier ID\").alias(\"supplierID\"),\\\n",
    "                                       col(\"Supplier Name\").alias(\"supplierName\"),\\\n",
    "                                        col(\"Supplier Country Code\").alias(\"supplierCountryID\")).distinct()\n",
    "dimSupplier.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- supplierID: string (nullable = true)\n",
      " |-- supplierName: string (nullable = true)\n",
      " |-- supplierCountryID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check the format of datatype \n",
    "dimSupplier.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dimProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5504"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check distinct rows \n",
    "df_product_transform.select(col(\"Product ID\").alias(\"produdctID\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gennerate dimProdcutable\n",
    "dimProduct = df_product_transform.select(col(\"Product ID\").alias(\"productID\"),\\\n",
    "                                         col(\"Product Name\").alias(\"productName\"),\\\n",
    "                                         col(\"Product Group\").alias(\"productGroup\"),\\\n",
    "                                         col(\"Product Line\").alias(\"productLine\"),\\\n",
    "                                         col(\"Product Category\").alias(\"productCategory\"),\\\n",
    "                                        col(\"Supplier ID\").alias(\"supplierID\")\n",
    ").distinct()\n",
    "                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 245:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+-----------+---------------+----------+\n",
      "|   productID|         productName|        productGroup|productLine|productCategory|supplierID|\n",
      "+------------+--------------------+--------------------+-----------+---------------+----------+\n",
      "|210200300097|Tony's Sweatshirt...|Eclipse, Kid's Cl...|   Children|Children Sports|      1303|\n",
      "|210200300109|Tony's Unbrushed ...|Eclipse, Kid's Cl...|   Children|Children Sports|      1303|\n",
      "|210200600004|College Sweat Hoo...|     N.D. Gear, Kids|   Children|Children Sports|     14682|\n",
      "|210200600025|Kid Tracking Pant...|     N.D. Gear, Kids|   Children|Children Sports|     14682|\n",
      "|210200600094|       Junior Shorts|     N.D. Gear, Kids|   Children|Children Sports|      4742|\n",
      "+------------+--------------------+--------------------+-----------+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dimProduct.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- productID: string (nullable = true)\n",
      " |-- productName: string (nullable = true)\n",
      " |-- productGroup: string (nullable = true)\n",
      " |-- productLine: string (nullable = true)\n",
      " |-- productCategory: string (nullable = true)\n",
      " |-- supplierID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check datatype \n",
    "dimProduct.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5504"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimProduct.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dimCustomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56027"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_order_transform.select(col(\"Customer ID\").alias(\"customerID\")).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimCustomer = df_order_transform.select(col(\"Customer ID\").alias(\"customerID\")).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56027"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimCustomer.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:>                                                         (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|customerID|\n",
      "+----------+\n",
      "|     74605|\n",
      "|     40740|\n",
      "|     90143|\n",
      "|     17427|\n",
      "|     50254|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dimCustomer.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dimCustomerStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "dimCustomerStatus = df_order_transform.select(col(\"Customer ID\").alias(\"customerID\"),\\\n",
    "                                        col(\"Customer Status\").alias(\"customerStatus\")\n",
    ").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimCustomerStatus = dimCustomerStatus.withColumn(\"customerStatusID\", monotonically_increasing_id() + 100).\\\n",
    "                                        withColumn(\"customerStatusID\", col(\"customerStatusID\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimCustomerStatus = dimCustomerStatus.select(\"customerStatusID\", \"customerID\", \"customerStatus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 248:===================>                                     (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+--------------+\n",
      "|customerStatusID|customerID|customerStatus|\n",
      "+----------------+----------+--------------+\n",
      "|             100|     49016|          Gold|\n",
      "|             101|     59620|        Silver|\n",
      "|             102|     91893|        Silver|\n",
      "|             103|     88779|        Silver|\n",
      "|             104|     56163|        Silver|\n",
      "+----------------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dimCustomerStatus.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerStatusID: string (nullable = false)\n",
      " |-- customerID: string (nullable = true)\n",
      " |-- customerStatus: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check data type\n",
    "dimCustomerStatus.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dimDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNION order date and delivery date to generate date table\n",
    "df_order_date = df_order_transform.select(\"Order Date\").distinct()\n",
    "df_delivery_date = df_order_transform.select(\"Delivery Date\").distinct()\n",
    "df_date = df_order_date.union(df_delivery_date).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1840"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_date.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Order Date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_date.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Order Date|\n",
      "+----------+\n",
      "|2017-08-11|\n",
      "|2017-09-11|\n",
      "|2018-05-28|\n",
      "|2018-08-10|\n",
      "|2019-05-08|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_date.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, quarter\n",
    "#create dimDate table\n",
    "dimDate = df_date.withColumn(\"day\", dayofmonth(\"Order Date\")).\\\n",
    "                    withColumn(\"month\", month(\"Order Date\")).\\\n",
    "                    withColumn(\"quarter\", quarter(\"Order Date\")).\\\n",
    "                    withColumn(\"year\", year(\"Order Date\")).\\\n",
    "                    withColumnRenamed(\"Order Date\", \"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save file as parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 144:======================================>                  (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 147:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+-----+-------+----+\n",
      "|      date|day|month|quarter|year|\n",
      "+----------+---+-----+-------+----+\n",
      "|2017-08-11| 11|    8|      3|2017|\n",
      "|2017-09-11| 11|    9|      3|2017|\n",
      "|2018-05-28| 28|    5|      2|2018|\n",
      "|2018-08-10| 10|    8|      3|2018|\n",
      "|2019-05-08|  8|    5|      2|2019|\n",
      "+----------+---+-----+-------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dimDate.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- quarter: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimDate.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "factOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Customer ID: string (nullable = true)\n",
      " |-- Customer Status: string (nullable = true)\n",
      " |-- Order Date: date (nullable = true)\n",
      " |-- Delivery Date: date (nullable = true)\n",
      " |-- Order ID: string (nullable = true)\n",
      " |-- Product ID: string (nullable = true)\n",
      " |-- Order Quantity: integer (nullable = true)\n",
      " |-- Order Price: double (nullable = true)\n",
      " |-- Cost Per Product: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_order_transform.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_fact_order = df_order_transform.select(col(\"Order ID\").alias(\"orderID\"),\\\n",
    "                                        col(\"Customer ID\").alias(\"customerID\"),\\\n",
    "                                        col(\"Customer Status\").alias(\"customerStatus\"),\\\n",
    "                                        col(\"Order Date\").alias(\"orderDate\"),\\\n",
    "                                        col(\"Order Price\").alias(\"orderPrice\"),\\\n",
    "                                        col(\"Delivery Date\").alias(\"deliveryDate\"),\\\n",
    "                                        col(\"Cost Per Product\").alias(\"costPerProduct\"),\\\n",
    "                                        col(\"Order Quantity\").alias(\"orderQuantity\"),\\\n",
    "                                        col(\"Product ID\").alias(\"productID\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 214:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------+----------+----------+------------+--------------+-------------+------------+\n",
      "|  orderID|customerID|customerStatus| orderDate|orderPrice|deliveryDate|costPerProduct|orderQuantity|   productID|\n",
      "+---------+----------+--------------+----------+----------+------------+--------------+-------------+------------+\n",
      "|123009195|     92956|        Silver|2017-01-02|     226.2|  2017-01-02|          58.9|            2|230100100013|\n",
      "|123013358|     62039|          Gold|2017-01-03|      41.2|  2017-01-03|          20.7|            1|220100100036|\n",
      "|123024632|     40267|        Silver|2017-01-05|      34.8|  2017-01-05|          14.9|            1|210200600084|\n",
      "|123037269|     50664|          Gold|2017-01-07|      84.6|  2017-01-07|         18.45|            2|240800200043|\n",
      "|123034300|     55786|        Silver|2017-01-07|      83.7|  2017-01-07|          41.8|            1|210200600013|\n",
      "+---------+----------+--------------+----------+----------+------------+--------------+-------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_fact_order.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerStatusID: string (nullable = false)\n",
      " |-- customerID: string (nullable = true)\n",
      " |-- customerStatus: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dimCustomerStatus.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- orderID: string (nullable = true)\n",
      " |-- customerID: string (nullable = true)\n",
      " |-- customerStatus: string (nullable = true)\n",
      " |-- orderDate: date (nullable = true)\n",
      " |-- orderPrice: double (nullable = true)\n",
      " |-- deliveryDate: date (nullable = true)\n",
      " |-- costPerProduct: double (nullable = true)\n",
      " |-- orderQuantity: integer (nullable = true)\n",
      " |-- productID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fact_order.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp view to implement sparkSQL\n",
    "df_fact_order.createOrReplaceTempView(\"order_table\")\n",
    "dimCustomerStatus.createOrReplaceTempView(\"customerStatus_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 215:======================================>                  (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 217:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------+----------+----------+------------+--------------+-------------+------------+\n",
      "|  orderID|customerID|customerStatus| orderDate|orderPrice|deliveryDate|costPerProduct|orderQuantity|   productID|\n",
      "+---------+----------+--------------+----------+----------+------------+--------------+-------------+------------+\n",
      "|123009195|     92956|        Silver|2017-01-02|     226.2|  2017-01-02|          58.9|            2|230100100013|\n",
      "|123013358|     62039|          Gold|2017-01-03|      41.2|  2017-01-03|          20.7|            1|220100100036|\n",
      "|123024632|     40267|        Silver|2017-01-05|      34.8|  2017-01-05|          14.9|            1|210200600084|\n",
      "|123037269|     50664|          Gold|2017-01-07|      84.6|  2017-01-07|         18.45|            2|240800200043|\n",
      "|123034300|     55786|        Silver|2017-01-07|      83.7|  2017-01-07|          41.8|            1|210200600013|\n",
      "+---------+----------+--------------+----------+----------+------------+--------------+-------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from order_table\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 197:=========================================================(3 + 0) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+----------------+\n",
      "|customerID|customerStatus|customerStatusID|\n",
      "+----------+--------------+----------------+\n",
      "|     49016|          Gold|             100|\n",
      "|     59620|        Silver|             101|\n",
      "|     91893|        Silver|             102|\n",
      "|     88779|        Silver|             103|\n",
      "|     56163|        Silver|             104|\n",
      "+----------+--------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from customerStatus_table\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate factOrder table by using JOiN in sparkSQL\n",
    "factOrder = spark.sql(\"\"\"\n",
    "        select o.orderID, o.orderPrice, o.costPerProduct, o.orderQuantity, o.orderDate, o.deliveryDate, c.customerStatusID, productID\n",
    "        from order_table o\n",
    "        join customerStatus_table c\n",
    "        on o.customerStatus = c.customerStatus and o.customerID = c.customerID\n",
    "        \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 251:=====>           (1 + 2) / 3][Stage 252:>                (0 + 2) / 3]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 256:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------+-------------+----------+------------+----------------+------------+\n",
      "|  orderID|orderPrice|costPerProduct|orderQuantity| orderDate|deliveryDate|customerStatusID|   productID|\n",
      "+---------+----------+--------------+-------------+----------+------------+----------------+------------+\n",
      "|123009195|     226.2|          58.9|            2|2017-01-02|  2017-01-02|           31768|230100100013|\n",
      "|123013358|      41.2|          20.7|            1|2017-01-03|  2017-01-03|           16661|220100100036|\n",
      "|123024632|      34.8|          14.9|            1|2017-01-05|  2017-01-05|           13138|210200600084|\n",
      "|123037269|      84.6|         18.45|            2|2017-01-07|  2017-01-07|           28716|240800200043|\n",
      "|123034300|      83.7|          41.8|            1|2017-01-07|  2017-01-07|           23032|210200600013|\n",
      "|123062708|     165.5|         82.85|            1|2017-01-12|  2017-01-12|           34157|220200100229|\n",
      "|123069200|      18.2|           8.2|            1|2017-01-13|  2017-01-13|           13804|220101000001|\n",
      "|123071854|      17.1|          7.65|            1|2017-01-14|  2017-01-14|           20091|210201000086|\n",
      "|123079099|      35.7|         17.95|            1|2017-01-15|  2017-01-20|           34939|220100100135|\n",
      "|123094799|      46.1|         19.55|            1|2017-01-18|  2017-01-18|           15302|210200900001|\n",
      "|123004763|      16.0|           6.5|            1|2017-01-20|  2017-01-20|           40503|240600100010|\n",
      "|123003344|     270.5|         23.85|            5|2017-01-20|  2017-01-20|            2953|240100100528|\n",
      "|123004819|      64.2|          32.2|            1|2017-01-20|  2017-01-20|           21768|230100600018|\n",
      "|123017050|      25.7|          12.8|            1|2017-01-22|  2017-01-22|            7916|220101400371|\n",
      "|123027662|      36.8|          16.0|            1|2017-01-24|  2017-01-24|            1452|240600100181|\n",
      "|123029429|      17.7|           8.0|            1|2017-01-24|  2017-01-24|           29143|220101000002|\n",
      "|123042446|      36.3|          15.2|            1|2017-01-27|  2017-01-27|           35739|210200600116|\n",
      "|123047317|     220.0|         135.0|            1|2017-01-27|  2017-01-27|           40914|230100700002|\n",
      "|123060420|      86.2|         39.25|            1|2017-01-30|  2017-01-30|           15523|220200200011|\n",
      "|123073140|      96.4|         43.85|            1|2017-02-01|  2017-02-01|           10340|220200200032|\n",
      "+---------+----------+--------------+-------------+----------+------------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "factOrder.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- orderID: string (nullable = true)\n",
      " |-- orderPrice: double (nullable = true)\n",
      " |-- costPerProduct: double (nullable = true)\n",
      " |-- orderQuantity: integer (nullable = true)\n",
      " |-- orderDate: date (nullable = true)\n",
      " |-- deliveryDate: date (nullable = true)\n",
      " |-- customerStatusID: string (nullable = false)\n",
      " |-- productID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check datatype \n",
    "factOrder.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 235:==========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185013 185013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(df_order.count(), factOrder.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load stage 2 files to HDSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df_to_hdfs(df, hdfs_path):\n",
    "    df.repartition(1).write.mode('overwrite').parquet(f\"{hdfs_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_directory = \"hdfs://localhost:9000/sales-analytics-data/completely-transformed-data\"\n",
    "file_format = \"parquet\"\n",
    "\n",
    "tables = [factOrder, dimDate, dimCustomerStatus, dimCustomer, dimProduct, dimSupplier, dimCountry]\n",
    "\n",
    "hdfs_paths = [f\"{hdfs_directory}/factOrder.{file_format}\", \n",
    "             f\"{hdfs_directory}/dimDate.{file_format}\", \n",
    "             f\"{hdfs_directory}/dimCustomerStatus.{file_format}\", \n",
    "             f\"{hdfs_directory}/dimCustomer.{file_format}\", \n",
    "             f\"{hdfs_directory}/dimProduct.{file_format}\", \n",
    "             f\"{hdfs_directory}/dimSupplier.{file_format}\", \n",
    "             f\"{hdfs_directory}/dimCountry.{file_format}\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdfs://localhost:9000/sales-analytics-data/completely-transformed-data/factOrder.parquet\n",
      "hdfs://localhost:9000/sales-analytics-data/completely-transformed-data/dimDate.parquet\n",
      "hdfs://localhost:9000/sales-analytics-data/completely-transformed-data/dimCustomerStatus.parquet\n",
      "hdfs://localhost:9000/sales-analytics-data/completely-transformed-data/dimCustomer.parquet\n",
      "hdfs://localhost:9000/sales-analytics-data/completely-transformed-data/dimProduct.parquet\n",
      "hdfs://localhost:9000/sales-analytics-data/completely-transformed-data/dimSupplier.parquet\n",
      "hdfs://localhost:9000/sales-analytics-data/completely-transformed-data/dimCountry.parquet\n"
     ]
    }
   ],
   "source": [
    "for i in hdfs_path:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 339:===================>                                     (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load succesfully no.0 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load succesfully no.1 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load succesfully no.2 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load succesfully no.3 files\n",
      "Load succesfully no.4 files\n",
      "Load succesfully no.5 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 385:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load succesfully no.6 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(tables):\n",
    "    write_df_to_hdfs(df, hdfs_paths[i])\n",
    "    print(f\"Load succesfully no.{i} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load to data warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
